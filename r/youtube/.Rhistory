# Carregar o arquivo CSV no ambiente global
meu_dataframe <- read.csv("Global YouTube Statistics.csv")
# Visualizar as primeiras linhas do dataframe
head(meu_dataframe)
View(meu_dataframe)
# Filtrar as observações onde a coluna 'Abbreviation' é igual a 'BR'
novo_dataframe <- subset(meu_dataframe, Abbreviation == "BR")
# Visualizar as primeiras linhas do novo dataframe
head(novo_dataframe)
View(novo_dataframe)
View(meu_dataframe)
# Contar a frequência de cada valor único na coluna 'category'
frequencia_category <- table(meu_dataframe$category)
# Converter a tabela em um dataframe
frequencia_category_df <- as.data.frame(frequencia_category)
# Renomear as colunas do dataframe
colnames(frequencia_category_df) <- c("Category", "Frequency")
# Visualizar o dataframe
head(frequencia_category_df)
View(frequencia_category_df)
View(novo_dataframe)
View(meu_dataframe)
# Obter o número total de observações na coluna 'category'
total_observacoes <- nrow(meu_dataframe)
# Calcular a porcentagem de frequência para cada valor único
porcentagem_category <- (frequencia_category / total_observacoes) * 100
# Converter a tabela em um dataframe
porcentagem_category_df <- as.data.frame(porcentagem_category)
# Renomear as colunas do dataframe
colnames(porcentagem_category_df) <- c("Category", "Percentage")
# Visualizar o dataframe
head(porcentagem_category_df)
View(frequencia_category_df)
View(porcentagem_category_df)
# Renomear os dataframes
dados_completos <- meu_dataframe
dados_filtrados_BR <- novo_dataframe
categoria_frequencia <- frequencia_category_df
categoria_porcentagem_frequencia <- porcentagem_category_df
# Opcional: Remover os dataframes antigos para liberar memória
rm(meu_dataframe, novo_dataframe, frequencia_category_df, porcentagem_category_df)
View(categoria_frequencia)
View(categoria_porcentagem_frequencia)
View(dados_completos)
View(dados_filtrados_BR)
View(dados_completos)
# Contar a frequência de cada país na coluna 'Country'
frequencia_paises <- table(dados_completos$Country)
# Ordenar em ordem decrescente
frequencia_paises_ordenada <- sort(frequencia_paises, decreasing = TRUE)
# Converter a tabela ordenada em um dataframe
paises_mais_frequentes <- as.data.frame(frequencia_paises_ordenada)
# Renomear as colunas do dataframe
colnames(paises_mais_frequentes) <- c("Country", "Frequency")
# Visualizar o dataframe
head(paises_mais_frequentes)
View(paises_mais_frequentes)
# Contar a frequência de cada valor único na coluna 'channel_type'
frequencia_channel_type <- table(dados_completos$channel_type)
# Obter o número total de observações na coluna 'channel_type'
total_observacoes_channel_type <- nrow(dados_completos)
# Calcular a porcentagem de frequência para cada valor único
porcentagem_channel_type <- (frequencia_channel_type / total_observacoes_channel_type) * 100
# Converter a tabela de frequência em um dataframe
channel_type_frequencia <- as.data.frame(frequencia_channel_type)
# Converter a tabela de porcentagem em um dataframe
channel_type_porcentagem_frequencia <- as.data.frame(porcentagem_channel_type)
# Renomear as colunas dos dataframes
colnames(channel_type_frequencia) <- c("Channel_Type", "Frequency")
colnames(channel_type_porcentagem_frequencia) <- c("Channel_Type", "Percentage")
# Visualizar os dataframes
head(channel_type_frequencia)
head(channel_type_porcentagem_frequencia)
View(channel_type_frequencia)
View(channel_type_porcentagem_frequencia)
View(dados_completos)
# Calcular a correlação entre 'rank' e 'Unemployment.rate'
correlacao <- cor(dados_completos$rank, dados_completos$Unemployment.rate, use="complete.obs")
# Mostrar o valor da correlação
correlacao
# Calcular a correlação entre 'subscribers' e 'Unemployment.rate'
correlacao_subscribers <- cor(dados_completos$subscribers, dados_completos$Unemployment.rate, use="complete.obs")
# Mostrar o valor da correlação
correlacao_subscribers
# Carregar o pacote necessário
library(ggplot2)
# Criar um modelo de regressão polinomial de segundo grau
modelo_polinomial <- lm(Unemployment.rate ~ poly(subscribers, 2), data=dados_completos)
# Visualizar o resultado
ggplot(dados_completos, aes(x=subscribers, y=Unemployment.rate)) +
geom_point() +
geom_smooth(method="lm", formula=y ~ poly(x, 2), se=FALSE) +
ggtitle("Regressão Polinomial entre Inscritos e Taxa de Desemprego") +
xlab("Número de Inscritos") +
ylab("Taxa de Desemprego")
View(modelo_polinomial)
View(modelo_polinomial)
View(categoria_frequencia)
View(categoria_porcentagem_frequencia)
View(channel_type_frequencia)
View(channel_type_porcentagem_frequencia)
View(channel_type_frequencia)
View(dados_completos)
View(paises_mais_frequentes)
# Carregar o pacote necessário
library(readr)
# Ler o arquivo CSV
dados_completos <- read_csv("Caminho/para/seu/arquivo/Global YouTube Statistics.csv")
head(dados_completos)
# Resumo estatístico básico
summary(dados_completos)
# Verificar valores faltantes
sum(is.na(dados_completos))
# Distribuição dos canais por país
table(dados_completos$Country)
# Distribuição dos canais por tipo de canal
table(dados_completos$channel_type)
# Correlação entre variáveis numéricas
cor(dados_completos[,sapply(dados_completos, is.numeric)], use="complete.obs")
# Verificar valores faltantes
sum(is.na(dados_completos$channel_type))
sum(is.na(dados_completos$Unemployment.rate))
# Resumo estatístico para identificar outliers
summary(dados_completos$Unemployment.rate)
library(dplyr)
dados_agrupados <- dados_completos %>%
group_by(channel_type) %>%
summarise(Avg_Unemployment = mean(Unemployment.rate, na.rm = TRUE))
# Visualizar os dados agrupados
dados_agrupados
View(dados_agrupados)
library(ggplot2)
ggplot(dados_agrupados, aes(x = channel_type, y = Avg_Unemployment)) +
geom_bar(stat = "identity") +
xlab("Tipo de Canal") +
ylab("Taxa de Desemprego Média") +
ggtitle("Taxa de Desemprego Média por Tipo de Canal")
anova_result <- aov(Unemployment.rate ~ channel_type, data = dados_completos)
summary(anova_result)
View(anova_result)
